\chapter*{Formulierung von Parameterschätzproblemen}

englisch: Parameter Estimation

Beispiel: Chemische Reaktion ("`Bimolekulare Katalyse"'), zwei Stoffe reagieren zu einem dritten:

\[A+B \to C\]

Es gibt zwei sogenannte Reaktionspfade, einen mit Katalysator und einen ohne Katalysator, beide Pfade laufen parallel ab und die Konzentrationsänderungen durch die beiden Pfade werden addiert. Wir nennen den Reaktionsgeschwindigkeitskoeffizienten $k_1$ für die Reaktion ohne Katalysator bzw. $k_2$ für die Reaktion mit Katalysator.

\[k_1 = f_1 \exp\l(-\frac{E_1}{RT}\r)\]

Die Wirkung des Katalysators nimmt mit der Zeit ab, das wird durch eine Exponentialfunktion beschrieben:

\[k_2 = c_{kat} \exp(-\lambda t) f_2 \exp\l(-\frac{E_2}{RT}\r)\]

Reaktionsgeschwindigkeit: $r= k_1 c_1 c_2 + k_2 c_1 c_2$

Daraus ergibt sich ein DGL-System mit Anfangsbedingungen:

\begin{align*}
\dot n_1 &= -V(k_1+k_2) \frac{n_1}V \frac{n_2}V \\
\dot n_2 &= -V(k_1+k_2) \frac{n_1}V \frac{n_2}V \\
\dot n_3 &= -V(k_1+k_2) \frac{n_1}V \frac{n_2}V \\
n_1(0) &= n_{1,0} \\
n_2(0) &= n_{2,0} \\
n_3(0) &= 0 \\
\end{align*}

Wobei $n_1$ die Anzahl Moleküle des ersten Stoffes beschreibt und $V$ das Gesamt-Volumen aller an dem Experiment beteiligter Stoffe.

% ###### Bild 1

Der Prozessverlauf wird bestimmt von Größen, die von dem Experminentator eingestellt werden: $T,V,n_{1,0},n_{2,0}$. Diese nennen wir "`Steuergrößen"'
Außerdem hängt der Verlauf auch von den Größen $f_1,E_1,f_2,E_2,\lambda$ ab. Diese Größen sind durch Naturgesetze, Stoffeigenschaften etc. bestimmte Größen, diese nennen wir "Parameter", sie sind nicht zeitabhängig.

\emph{Experiment:} Wähle Steuerungen, führe Prozess durch, erhebe Messdaten und Messfehler. Die Messdaten hier liefert eine Apparatur zur Messung von C.

% ###### Bild 2

\emph{Parameterschätzung:} Bestimme die Werte der unbekannten Modellparameter so, dass die Simulation die Messwerte möglichst gut beschreibt.

\section*{Problemformulierung}

\subsection*{Prozessmodell}

\[\dot y = f(t,y(t),\overline p) \quad y(t_0) = y_0(\overline p) \quad (2.1)\]

\subsection*{Modell für Beobachtungen}

\begin{itemize}
\item Nicht notwendigerweise verschiedene Messzeitpunkte $t_i$, $i=1,\cdots,M$
\item Messwerte $\eta_i \in \R$ und zugehörige Modellantworten $h_i (t_i, y(t_i), \overline p) \in \R$
\item Messfehler $\eps_i \in \R$ mit Standardabweichung $\sigma_i \in \R_+$
\end{itemize}

$\overline p$ seien die wahren, aber unbekannten Werte der Parameter.

\emph{Annahme:} Die Messfehler seien unabhängige, additive und normalverteilte Zufallsgrößen mit bekannter Standardabweichung:

\begin{align*}
\eta_i &= h_i(t_i, y(t_i), \overline p) + \eps_i \quad (2.2) \\
\eps_i &\sim \mathcal N(0, \sigma_i^2) \quad (2.3)
\end{align*}

Erwartungswert $0$ bedeutet, dass es keinen systematischen Messfehler gibt.

\emph{Bemerkung:} Da die Messzeitpunkte nicht notwendig verschieden sind, kann es an einem Zeitpunkt $t$ auch mehrere Messungen geben. Auch die Messfunktionen $h_i$ sind nicht notwendig verschieden.

Beispiele für die Standardabweichung $\sigma:$

\begin{itemize}
\item absolute Messfehler: $\sigma_i \equiv \sigma$
\item relative Messfehler: $\sigma_i =  \frac x{100} \l| h_i(t_i,y(t_i),\overline p) \r| \sim \frac x{100} \l|\eta_i\r|$
\end{itemize}

Wichtig: Zur Beschreibung von Messdaten benötigt man Messwert $\eta$ und "`Genauigkeit"' (Standardabweichung) $\sigma$. Wenn man die wahren Parameter $\overline p$ nicht kennt kann man trotzdem immernoch die Residuen $\eta_i-h_i(t_i,y(t_i), \overline p)$, $i=1,\cdots,M$ oder die gewichteten Residuen $\sigma_i^{-1}(\eta_i-h_i(t_i,y(t_i), \overline p))$, $i=1,\cdots,M$ $(2.4)$  betrachten.

\emph{Ziel der Parameterschätzung:} passe Modell an die Daten an.

\emph{Möglicher Ansatz:} Maximum Likelihood, d.\,h. suche die Parameter, unter denen die beobachteten Daten die höchste Wahrscheinlichkeit haben. Das ist der ML-Schätzer $\hat p$:

\[\hat p = \argmax_p L(p)\]

Mit der Likelihood-Funktion $L(p)$, die die bedingte Wahrscheinlichkeit der Daten in Abhängigkeit von den Parametern angibt. Oft betrachtet man die sogenannte log-Likelihood-Funktion $\log L$. Für unabhängige, normalverteilte Messfehler gilt:

\begin{align*}
\hat p &= \argmax_p \log L(p)\\
&= \argmax_p \log \prod_{i=1}^M \frac 1{\sqrt{2\pi \sigma_i^2}} \exp\l( -\frac 12 \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 \r) \\
&= \argmax_p \sum_{i=1}^M \log \l[\frac 1{\sqrt{2\pi \sigma_i^2}} \exp\l( -\frac 12 \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 \r)\r] \\
&= \argmax_p \sum_{i=1}^M -\log \sqrt{2\pi \sigma_i^2} + \log \exp\l( -\frac 12 \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 \r) \\
&= \argmax_p \sum_{i=1}^M -\frac 12 \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 - \sum_{i=1}^M \log \sqrt{2\pi \sigma_i^2} \\
&= \argmax_p - \frac 12 \sum_{i=1}^M \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 \\
&= \argmin_p \frac 12 \sum_{i=1}^M \l(\frac{\eta_i-h_i(t_i,y(t_i),p)}{\sigma_i} \r)^2 \quad (2.5)\\
\end{align*}

Also minimiert $\hat p$ die $\|\cdot\|_2$-Norm des Residuen-Vektors. Gleichzeitig müssen $y$ und $p$ das AWP $(2.1)$ erfüllen.

\emph{Parameterschätzproblem:}

\[\min_p \frac 12 \sum_{i=1}^M \l(\frac{\eta_i - h_i(t_i,y(t_i),p)}{\sigma_i}\r)^2\]

So dass gilt: $\dot y = f(t,y(t),p)$, $y(t_0) = y_0(p)$ (2.6).

Wichtig: Es werden immer Gewichte verwendet.

\begin{itemize}
\item Wenn man keine hat, macht man die Annahme, dass alle $\sigma_1 \equiv 1$
\item Ein gemeinsamer (positiver) Faktor an den verwendeten Gewichten ändert das Problen nicht.
\item Das Problem (2.6) und seine Lösung hängen sehr von den Gewichten ab.
\item Jede Wahl der Gewichte macht eine spezielle Annahme über die Statistik der Messfehler: $N(0,\sigma_i^2)$-verteilt.
\end{itemize}

\emph{Schreibweisen:}

\begin{align*}
\eta &= \begin{pmatrix} \eta_1 \\ \vdots \\ \eta_M \end{pmatrix} \\
h = h(y,p) &= \begin{pmatrix} h_1(t_1,y(t_1), p) \\ \vdots \\ h_M(t_M, y(t_M),p) \end{pmatrix} \\
\eps &= \begin{pmatrix} \eps_1 \\ \vdots \\ \eps_M \end{pmatrix}\\
S &= \begin{pmatrix} \sigma_1^2 & & 0 \\ & \ddots & \\ 0 & & \sigma_M^2 \end{pmatrix}
\end{align*}

Dann gilt: $\eps \sim N(0,S) \RA S^{-1/2} \eps \sim N(0,I)$

Das Zielfunktional von (2.6) minimiert

\[ \frac 12 \| S^{-\frac 12} (\eta-h)\|_2^2 = \frac 12 (\eta -h)^T S^{-1} (\eta-h) \quad (2.7) \]

$S$ heißt Kovarianzmatrix der Messfehler

\[S = E (\eps\eps^T) \quad \text{"`Erwartungswert von $\eps\eps^T$"'}\]

Für unabhängige normalverteilte Messfehler ist $S$ diagonal und positiv definit. Allgemeiner für unabhängige (korrelierte) multinomialverteile Messfehler ist $S$ symmetrisch und positiv definit.

\[ S=\begin{pmatrix} \sigma_1^2 & s_{ij} \\ s_{ji} & \sigma_M^2 \end{pmatrix} \]

mit Varianzen $\sigma_i^2$ und Kovarianzen $s_{ij}$. Zusätzlich definieren wir Korrelationskoeffizienten:

\begin{align*}
r_{ij} &= \frac{s_{ij}}{\sigma_i\sigma_j} \quad \text{Korrelation $-1 \leq r_{ij} \leq 1$} \\
R &= \begin{pmatrix} \sigma_1^{-1} & & 0 \\ & \ddots & \\ 0 & & \sigma_M^{-1} \end{pmatrix} S \begin{pmatrix} \sigma_1^{-1} & & 0 \\ & \ddots & \\ 0 & & \sigma_M^{-1} \end{pmatrix} \\
&= \begin{pmatrix} 1 & & r_{ij} \\ & \ddots & \\ r_{ji} & & 1 \end{pmatrix} \\
\end{align*}

R heißt Korrelationsmatrix. Für nicht-diagonales $S$ ist die ML-Schätzung gegeben durch

\[ \min (\eta-h(y,p))^T S^{-1} (\eta-h(y,p)) \quad (2.8)\]

Transformation: Zerlege $S$ = $LDL^T$ und minimiere folgendes:

\begin{align*}
\frac 12 (\eta -h)^T S^{-1} (\eta-h) &= \frac 12 (\eta-h)L^{-T} D^{-\frac 12} D^{-\frac 12} L^{-1} (\eta-h) \\
&= \frac 12 \|D^{-\frac 12} L^{-1}(\eta -h)\|_2^2 \quad (2.9) \\
D^{-\frac 12} L^{-1} (\eta -h(y,\overline p)) &\sim \mathcal N(0,I)
\end{align*}

Andere Messverteilungen:

Dichte:

\[\exp\l(-\l(\frac{|\eps|}{\sigma}\r)^q\r) \quad (2.10)\]

Schätzer:

\[ \min \|S^{-\frac 12} (\eta-h(y,p)) \|_q \quad (2.11)\]

Beispiele:

\emph{"`Robuste Parameterschätzung"'}

\begin{align*}
q &= 1 \\
& \min \sum_{i=1}^M \l| \frac{\eta_i-h_i(y,p)}{\sigma_i} \r| \quad (2.12)
\end{align*}


\emph{"`Worst-Case-Parameterschätzung"'}

\begin{align*}
q &= \infty \\
& \min \max_{i=1,\cdots,M} \l\{ \l| \frac{\eta_i-h_i(y,p)}{\sigma_i} \r| \r\} \quad (2.13)
\end{align*}

Nebenbedingung des Parameterschätzproblems:

\begin{itemize}
\item $y,p$ müssen die ODE-Modellgleichungen erfüllen: $\dot y = f(t,y,p)$ \\
Variante: $y,z,p$ müssen ein DAE erfüllen $\dot y = f(t,y,z,p)$, $0=g(t,y,z,p)$
\item Anfangsbedingung: Konsistenzbedingung $y(t_0) = y_0(p)$, im DAE-Fall zusätzlich $0=g(t_0,y_0,z(t_0),p)$
\item Randbedingungen $r(y(t_0),y(t_{end}),p) = 0$ oder auch $r(y(t_0),y(t_1),\cdots,y(t_{K-1}, y(t_{end}),p) = 0$
\end{itemize}


Beispiele und Spezialfälle:

\begin{itemize}
\item \emph{Periodizität:} $y(t_0) = y(t_{end})$.
\item \emph{Innere-Punkt-Bedingung:} $r(y(t_i),p) = 0$.
\item \emph{Linear gekoppelte Randbedingungen:} $r(y(t_0),p) + r(y(t_1),p) + \cdots + r(y(t_end),p) = 0$.
\item \emph{Ungleichsbendingungen:} $s(y(t_0), \cdots, y(t_k), p) \geq 0$, z.\,B. Vorzeichenbedingung $p_i \geq 0$ für einige $i$, Schranken $a_i \leq p_i \leq b_i$, Zustandsbeschränkungen $\overline y_i \geq y(t_i) \geq \underline y_i$
\end{itemize}

In einem effizienten numerischen Code sollten solche speziellen Strukturen berücksichtigt werden.

% Benutzername: numerik2 Passwort: iwr432



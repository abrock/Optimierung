% Wiederholen schadet nicht und vielleicht verstehen Sie es dieses Mal

\chaptr{5. Lokale Konvergenz von Newton-Typ-Verfahren}

Newton-Typ-Verfahren:

\bitm
\item Löse iterativ mit einem guten Startwert $x_0 \in \R^n$
\item Löse in jeder Iteration ein linearisiertes Problem
\item Wende eine Globalisierungsstrategie an
\eitm

\[ F\colon \R^n \to \R^m \quad M(x)\colon \text{ Lösungsoperator des linearen Problems} \]

\msection{Algorithmus 5.1 (Newton-Typ-Verfahren)}

\bitm
\item Startwert $x^0$, $k := 0$
\item Solange ein geeignetes Abbruchkriterium verletzt ist:
\bitm
	\item Berechne $\Delta x^k := - M(x^k) F(x^k)$ (5.1)
	\item Berechne $\alpha^k$ auf einer Globalisierungsstrategie
	\item Iteriere $x^{k+1} := x^k + \alpha^k \Delta x^k$ (5.2)
\eitm
\eitm

Kann angewendet werden:

\bitm
\item Zur Bestimmung von Nullstellen von $F(\cdot)$, $m=n$ $\RA$ Newton-Verfahren oder Quasi-Newton-Verfahren
\item Insbesondere zur Bestimmung von Nullstellen von $\Delta L(x,\lambda) = 0$ (notwendige Optimalitätsbedingung) $\RA$ SQP-Verfahren.
\item Zur Bestimmung von Lösungen unbeschränkter nichtlinearer Ausgleichsprobleme $\min \frac 12 \|F(x)\|_2^2$, $m \geq n$
\item Zur Bestimmung von Lösungen beschränkter nichtlinearer Ausgleichsprobleme $\min \frac 12 \|F_1(x)\| \text{ s.\,t. } F_2(x) = 0$, $m = m_1+m_2 \geq n$, $m_2 \leq n$ $\RA$ Verallgemeinertes Gauß-Newton-Verfahren.
\eitm

\[ \text{Sei } J := \frac{\partial F}{\partial x} \quad (5.3) \text{ Jacobimatrix} \]

\msubsection{Bemerkung 5.2}

\bitm
\item Bei Newton-Verfahren ist $M(x) = J(x)^{-1}$ die Inverse von $J$.
\item bei Quasi-Newton-Verfahren ist $M(x) \cong J(x)^{-1}$
\item Bei SQP-Verfahren ist $M(x, \lambda) = \nabla_{x,\lambda}^2 L(x, \lambda)^{-1}$ oder 
$M(x, \lambda) \cong \nabla_{x,\lambda}^2 L(x, \lambda)^{-1}$
\item Bei Gauß-Newton-Verfahren ist $M(x) = (J(x)^T J(x))^{-1} J(x)^T$ die Moore-Penrose-Pseudoinverse.
\eitm

































































































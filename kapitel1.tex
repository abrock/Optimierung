\chaptr{1. Parameterabhängige Anfangswertprobleme}

\emph{Parameterabhängige gewöhnliche Differentialgleichung} mit Parametervektor $p$ und parameterabhängiger Anfangsbedingung:

\begin{align*}
\dot y(t) &= f(t,y(t),p) & (1.1) \\
y(t_0) &= y_0(p) & (1.2)
\end{align*}

wobei

\begin{itemize}
\item $t \in [t_0,t_{end}]$ "`Zeit"'
\item $y\colon [t_0,t_{end}] \to \R^{n_y}$ "`Zustände"'
\item $p \in \R^{n_p}$ "`Parameter"'
\item $f\colon [t_0,t_{end}] \times \R^{n_y} \times \R^{n_p} \to \R^{n_y}$ sei hinreichend oft in $t$, $y$ (stückweise) stetig differenzierbar, damit numerische Integrationsverfahren mit Fehlerkontrolle funktionieren, außerdem einmal in $p$ stetig differenzierbar.
\item $y_0\colon \R^{n_p} \to \R^{n_y}$ einmal stetig differenzierbar.
\end{itemize}

\emph{Variante: } Differentiell-algebraische Gleichungssysteme (DAE):

\begin{align*}
f&\colon [t_0,t_{end}] \times \R^{n_y} \times \R^{n_z} \times \R^{n_p} \to \R^{n_y} & \\
g&\colon [t_0,t_{end}] \times \R^{n_y} \times \R^{n_z} \times \R^{n_p} \to \R^{n_z} & \\
\dot y &= t(t,y,z,p) & (1.3)\\
0 &= g(t,y,z,p) \\
y &\colon [t_0,t_{end}] \to \R^{n_y} & \text{differentielle Zustände} \\
z &\colon [t_0,t_{end}] \to \R^{n_z} & \text{algebraische Zustände} \\
\end{align*}

Das DAE benötigt nur Anfangswerte für $y$:

\begin{align*}
y(t_0) &= y_0(p) & (1.4)
\end{align*}

Die Anfangswerte der $z$ sind durch die \empha{Konsistenzbedingung} gegeben:

\begin{align*}
g(t_0,y(t_0), z(t_0),p)&=0 & (1.5)
\end{align*}

Wir betrachten in dieser Vorlesung nur den \empha{Index-1-Fall}, d.\,h.

\begin{align*}
\frac{\partial_g}{\partial_z} \quad \text{hat den Rang } n_z & & (1.6)
\end{align*}

Daraus folgt, dass die algebraischen Gleichungen lokal eindeutig nach $\dot z$ auflösbar sind:

\begin{align*}
0 &= g(t,y,z,p) \\
0 &= \frac\partial{\partial t} g(t,y,z,p) \\
&= \frac{\partial g}{\partial t} + \frac{\partial g}{\partial y} \dot y + \frac{\partial g}{\partial z} \dot z \\
\dot z &= -\l(\frac{\partial g}{\partial z}\r)^{-1} \l(\frac{\partial g}{\partial t} + \frac{\partial g}{\partial y} \dot y \r)
\end{align*}

Man erhält zusammen mit $\dot y = f$ eine ODE für $y$ und $z$, deren Anfangswerte aber die Konsistenzbedingung $(1.5)$ erfüllen müssen. Diese ODE- bzw. DAE-Anfangswertprobleme können auch aus im Ort diskretisierten Anfangs-(Rand-)Wertproblemen von instationären partiellen Differentialgleichungen kommen. In dieser Vorlesung behandeln wir nicht die Diskretisierungsmethoden für PDEs.

\emph{Satz 1.1:} Lokaler Stabilitätssatz

Seien die beiden Anfangswertprobleme

\begin{align*}
\dot u(t) &= f(t,u,p_1), \quad u(t_0) = u_0 & (1.7) \\
\dot v(t) &= f(t,v,p_1), \quad v(t_0) = v_0 & (1.8) \\
\end{align*}

auf $[t_0,t_{end}]$ gegeben. Die Funktion $f(t,y,p)$ sei stetig in $(t,y)$ und genüge einer Lipschitz-Bedingung in $y$ mit Konstante $L < \infty$. Dann gilt für die Lösungen $u$ und $v$ von $(1.7)$ und $(1.8)$:

\[ \|u(t)-v(t)\| \leq e^{L(t-t_{u})} \l(\|u_0-v_0\| + \int\limits_{t_0}^t \sup_{t,y} \|f( \tau, y(\tau), p_1) - f(\tau, y(\tau), p_2) \| \dd \tau\r)\]

Der Beweis wurde bereits in Numerik 1 gegeben, er benutzt das Gronwall-Lemma.

\emph{Korollar 1.2:} Trompetenabschätzung

Sei $f$ wie in Satz $1.1$ mit $L < \infty$. Für die Abweichung $\delta y \colon= v-y$ der Lösungen $y$ und $v$ von

\begin{align*}
\dot y(t) &= f(t,y,p), \quad y(t_0) = y_0(p) \\
\dot v(t) &= f(t,v,p_1), \quad v(t_0) = y_0(p + \delta p) \\
\end{align*}

gilt:

\[ \|\delta y(t) \| \leq \eps_1 e^{L(t-t_0)} + \eps_2 e^{L(t-t_0)}(t-t_0) \quad (1.10)\]

wobei

\begin{align*}
\|\delta y_0\| \colon&= \| \frac{\partial y_0}{\partial p} (p) \delta p \| \leq \eps_1 \\
\|\delta f\| \colon&= \| \frac{\partial f}{\partial p} (t,y,p) \partial p \| \leq \eps_2
\end{align*}

\emph{Beweis:}

Siehe Numerik 1, folgt aus Satz 1.1.

% Bild Trompetenabschätzung

Für Änderungen von $p$ können die Lösungen der Anfangswertprobleme exponentiell auseinanderlaufen. Kleine Störungen von $p$ in Anfangsbedingungen und Rechter-Seite-Funktion können sehr große Unterschiede in $y(t_{end})$ zur Folge haben.

\msection{Differentiation der Lösung des AWPs}

\emph{Schreibweise:}

Betrachte das Anfangswertproblem

\[ \dot y = f(t,y,p) \quad y(0) = y_0 \quad (1.11) \]

Die Lösung $y$ hängt von $t$, $t_0$, $y_0$ und $p$ ab. Wir schreiben:

\[ y(t) = y(t; t_0, y_0, p) \]

\emph{Satz 1.3:}

Sei $f \in \C^m$, $m \geq 1$. Dann ist $y(t; t_0, y_0, p)$

\begin{itemize}
\item (m+1) mal stetig differenzierbar in $t$
\item m mal stetig differenzierbar in $t_0$, $y_0$, $p$
\end{itemize}

\emph{Beweis:}

Integraldarstellung der Lösung:

\[ y(t) = y_0 + \int\limits_{t_0}^t f(\tau, y(\tau), y) \dd \tau \]

\emph{Definition 1.4:} Ableitungen der Lösung des AWP

\begin{itemize}
\item Ableitung nach Anfangswerten: $G(t; t_0, y_0, p) \colon= \tfrac{\partial}{\partial y_0} y(t; t_0, y_0, p)$
\item Ableitung nach Anfangszeitpunkt: $G_{t_0}(t; t_0, y_0, p) \colon= \frac{\partial}{\partial t_0} y(t; t_0, y_0, p)$
\item Ableitung nach Parametern: $G_p(t; t_0, y_0, p) \colon= \frac{\partial}{\partial p} y(t; t_0, y_0, p)$
\end{itemize}

\subsection*{Berechnung der Ableitungen:}

Integralform des AWP:

\[y(t) = y_0 + \int\limits_{t_0}^t f(\tau, y(\tau), p) \dd \tau \quad (1.12) \]

\subsubsection*{a) Differenziere nach Anfangswerten:}

\begin{align*}
\frac{\partial}{\partial y_0} y(t) &= \frac{\partial y_0}{\partial y_0} + \int\limits_{t_0}^t \frac{\partial}{\partial y} f(\tau, y(\tau), p) \frac{\partial y}{\partial y_0} (\tau) \dd \tau \\
G(t) &= I + \int\limits_{t_0}^t \frac{\partial}{\partial y} f(\tau, y(\tau), p) G(\tau) \dd \tau & (1.13)\\
\end{align*}

Dies ist äquivalent zum Anfangswertproblem

\begin{align*}
\dot G(t) &= \frac{\partial f}{\partial y} (t, y(t), p) G(t) & (1.14)\\
G(t_0) &= I
\end{align*}

zur sogenannten Variationsdifferentialgleichung (VDE) nach Anfangswerten.

\subsubsection*{Differenziere nach dem Anfangszeitpunkt:}

\begin{align*}
\frac{\partial}{\partial t_0} y(t) &= \frac{\partial y_0}{\partial t_0} + \frac{\partial}{\partial t_0} \int\limits_{t_0}^t f(\tau, y(\tau),p) \dd \tau \\
G_{t_0} (t) &= 0 - f(t_0, y(t_0), p) + \int\limits_{t_0}^t \frac{\partial f}{\partial y} G_{t_0} (\tau) \dd \tau & (1.15) \\
\end{align*}

Dies ist äquivalent zum Anfangswertproblem

\begin{align*}
\dot G(t_0) (t) &= \frac{\partial f}{\partial y} G_{t_0} (t) & (1.16) \\
G_{t_0} (t_0) &= -f(t_0 y(t_0), p) 
\end{align*}

zur VDE nach dem Anfangszeitpunkt.

\subsubsection*{c) Differenziere nach den Parametern:}

\begin{align*}
\frac \partial{\partial p} y(t) &= \frac{\partial y_0}{\partial p} + \int\limits_{t_0}^t \frac{\partial f}{\partial y} (\tau, y(\tau), p) \frac{\partial y}{\partial p} (\tau) + \frac{\partial f}{\partial p} (\tau, y(\tau), p) \dd \tau \\
G_p(t) &= \frac{\partial y_0}{\partial p} + \int\limits_{t_0}^t \frac{\partial f}{\partial y} G_p(\tau) + \frac{\partial f}{\partial p} \dd \tau & (1.17)
\end{align*}

Dies ist äquivalent zum Anfangswertproblem

\begin{align*}
\dot G_p(t) &= \frac{\partial f}{\partial y} (t,y(t),p) G_p(t) + \frac{\partial f}{\partial p} (t, y(t), p) \\
G_p(t_0) &= \frac{\partial y_0}{\partial p} & (1.18)
\end{align*}

zur VDE nach den Parametern.

\emph{Bemerkung 1.5:}

Die Anfangswertprobleme der VDEs (1.14), (1.16) und (1,18) hängen von der Lösung $y(t)$ des "`nominalen"' Anfangswertproblems (1.11) ab. Sie müssen also jeweils mit (1.11) in einem gemeinsamen System gelöst werden.

\emph{Satz 1.6}

Es gilt:

\[ G_{t_0} (t; t_0, y_0, p) = -G(t; t_0, y_0, p) f(t_0, y_0, p) \quad (1.19) \]

\emph{Beweis:}

Multipliziere $\dot G = \tfrac{\partial f}{\partial y} G$, $G(t_0) = I$ von rechts mit $-f(t_0, y_0, p):$

\begin{align*}
-\dot G f(t_0,y_0,p) &= -\frac{\partial f}{\partial y} G f(t_0, y_0, p) \\
\text{und } -G(t_0) f(t_0, y_0, p) &= -f(t_0, y_0, p)
\end{align*}

Also erfüllt $y \colon= -G f(t_0, y_0, p)$ die Differentialgleichung $\dot y = \tfrac{\partial f}{\partial y} y$ und die Anfangsbedingung $y(t_0) = -f(t_0, y_0, p)$. Das ist die VDE für $G_{t_0}$, also ist $y = -G f(t_0, y_0, p) = G_{t_0}$

\subsection*{Variationsdifferentialgleichungen für Richtungsableitungen}

Gegeben sei eine Richtung $\Delta y_0 \in \R^{n_y}$. Die Richtungsableitung von $y$ nach $y_0$ in der Richtung $\Delta y_0$ ist gegeben durch

\begin{align*}
\frac{\partial y}{\partial y_0} (t; t_0, y_0, p) \Delta y_0 \colon&= \l. \frac \partial{\partial h} y(t; t_0, y_0 + h \Delta y_0, p) \r|_{h=0} \\
&= \lim_{h \to 0} \frac{y(t; t_0, y_0 + h \Delta y_0, p) - y(t; t_0, y_0, p)}{h} \in \R^{n_y} & (1.19a)
\end{align*}

Die Richtungsableitung erfüllt

\begin{align*}
\frac{\partial}{\partial t}(G(t; t_0, y_0, p) \Delta y_0) &= \frac{\partial f}{\partial y} (t,y,p) (G(t;t_0,y_0,p)\Delta y_0) \\
G(t;t_0,y_0,p) \Delta y_0 &= I\Delta y_0 = \Delta y_0 & (1.20)
\end{align*}

Dies ist ein ($n_y$-dimensionales) VDE-Anfangswertproblem für jede Richtung $\Delta y_0$. hat man mehrere Richtungen, kann man diese spaltenweise in einer Richtungsmatrix $S$ zusammenfassen:

\[ S = ( \Delta y_{0,1}, \cdots, \Delta y_{y,n_s}) \]

Zur Berechnung aller zugehörigen Richtungsableitungen muss man also lösen:

\[ \dot{(GS)} = \frac{\partial f}{\partial y} (GS), \quad (GS)(t_0) = S \quad (1.21) \]

mit dem $n_s$-fachen Aufwand wie für eine Richtung. Für die gesamte Ableitung $\frac{\partial y}{\partial y_0} = \frac{\partial y}{\partial y_0} I_{n_y \times n_y}$ braucht man $n_y$ Richtungen, hat also den $n_y$-fachen Aufwand. Deshalb berechnet man Richtungsableitungen nicht durch Berechnen von $\frac{\partial y}{\partial y_0}$ und anschließende Multiplikation mit den Richtungen, sondern durch Lösen von Richtungs-VDE.

Für Richtungsableitungen nach $p$ analog:

\begin{align*}
\frac \partial{\partial t} (G_p(t;t_0,y_0,p) \Delta p) &= \frac{\partial f}{\partial y} (t,y,p) G_p(t;t_0,y_0,p) \Delta p + \frac{\partial f}{\partial p}(t,y,p) \\
G_p(t_0; t_0, y_0, p) \Delta p &= \frac{\partial y_0}{\partial p} \Delta p & (1.22) 
\end{align*}

\subsubsection*{Eigenschaften der Ableitungsmatrizen}

Füge an der Stelle $t_0 < s < t_end$ einen "`Haltepunkt"' ein:

\[\dot y = f(t,y,p),\quad t\in[s,t_{end}],\quad y(t_0) = y_0\]

und weiter

\[\dot y = f(t,y,p),\quad t\in[s,t_{end}],\quad y(s) = y(s; t_0, y_0, p) \]

Nach dem Satz von Picard-Lindelöff ist die abschnittsweise Lösung die selbe wie für

\[\dot y = f(t,y,t), t\in[t_0,t_{end}], y(t_0) = y_0 \]

\emph{Definition 1.7: Wronski-Matrix}

\[W(t,s) \colon= G(t; s, y_s, p) \]

\emph{Satz 1.8: Eigenschaften der Wronski-Matrizen}

\begin{itemize}
\item $W(t,s)$ erfüllt $\partial_t W(t,s) = \partial_y f(t,y,p) W(t,s)$, $W(s,s) = I$ 
\item $W(t,s) W(s,r) = W(t,r)$ (1.23)
\item Für alle $t,s,r \in [t_0, t_{end}]$ ist $W(t,s)$ invertierbar und es gilt $W(t,s)^{-1} = W(s,t)$ (1.24)
\item Für beliebige $t_1,\cdots,t_n$ ist $W(t_1,t_2)W(t_2,t_3) \cdots W(t_{n-1}, t_n) = W(t_1, t_n)$
\end{itemize}

\emph{Wronski-Matrizen für Ableitungen nach Parametern:}

\emph{Definition 1.9:}

\[ W_p(t,s) \colon= G_p(t;s,y_s,p)\]

\emph{Satz 1.10}

\[ W_p(t_{end},t_0) = W(t_{end},s) W_p(s,t_0)+W_p(t_{end},s) \quad (1.25) \]

\emph{Beweis:}

\begin{align*}
y(t_{end} &= y(t_{end}; t_0, y_0, p) = y(t_{end};s,y_s,p) \\
y_s &= y(s) = y(s; t_0,y_0,p) \\
W_p(t_{end},t_0) &= \frac{\partial y}{\partial y_s}(t_{end}; s,y_s,p) \cdot \frac{\partial y}{\partial p} (s;t_0,y_0,p) +\frac{\partial y}{\partial p}(\tend; s,y_s,p)\\
&= W(\tend,s) W_p(s,t_0) + w_p(\tend,s)
\end{align*}

\emph{Anwendung:}

Das System ODE+VDE wird abschnittsweise auf den Teilintervallen $[t_0,s]$, $[s;\tend]$ gelöst, liefert

\[y(s),\quad W(s,t_0), \quad W_p(s,t_0) \]

und

\[ y(\tend), \quad W(\tend,s), \quad W_p(\tend,s)\]

Dann kann man zusammensetzen:

\begin{align*}
W(\tend,t_0) &= W(\tend, s) W(s,t_0) \\
W_p(\tend,t_0) &= W(\tend, s) W_p(s,t_0) + W_p(\tend, s) 
\end{align*}

\subsection*{Ableitungsmatrizen bei abschnittsweise definierter rechter Seite}

\begin{align*}
\dot y(t) &= \begin{cases} f_1(t,y,p) & \text{ für } t < t_s \\ f_2(t,y,p) & \text{ für } t > t_s \end{cases} & (1.26)
y(t_0) = y_0
\end{align*}

Wobei der Umschaltpunkt $t_0 < t_s < t_{end}$ als eindeutige einfache Nullstelle der Schaltbedingung

\[ Q(t_s,y(t_s),p) = 0 \]

gegeben sei.

\emph{Satz 1.11}:

Dann gilt:

\begin{align*}
\frac{\partial y}{\partial y_0} (t_{end}; t_0,y_0,p) &= W(t_{end},t_s) \l[I-(f_1(t_s,y(t_s),p)-f_2(t_s,y(t_s),p)) \r. \\ 
& \l.\l( \frac{\partial Q}{\partial t} (t_s,y(t_s))\r)^{-1} \frac{\partial Q}{\partial y}(t_s,y(t_s)) \r] W(t_s,t_0) & (1.27) \\
\end{align*}

\emph{Beweis:}

\begin{align*}
y(t_{end} &= y(t_{end}; t_s,y_s,p) \\
y(t_s) &= y(t_s; t_0,y_0,p) \\
\frac{\partial y}{\partial y_0} &= \frac{\partial y}{\partial t_s} (t_{end}; t_s,y_s,p) \frac{\partial t_s}{\partial y_s} \frac{\partial y}{\partial y_0} (t_s; t_0,y_0,p) \\
&+ \frac{\partial y}{\partial y_s}(t_{end}) \l( \frac{\partial y(t_s)}{\partial y_0} + \l( \frac{\partial y(t_s)}{\partial t_s} \r) \frac{\partial t_s}{\partial y_s} \frac{\partial y}{\partial y_0}(t_s) \r) \\
\end{align*}

$t_s$ ist Endzeitpunkt des ersten und Anfangszeitpunkt des zweiten Intervalls.

\begin{align*}
0 &= Q(t_s,y(t_s),p) \\
\RA 0&= \l. \frac{\partial Q}{\partial t} \frac{\partial t}{\partial y} + \frac{\partial Q}{\partial y} \r|_{y=y_s} \\
\RA \frac{\partial t_s}{\partial y_s} &= \l. - \l(\frac{\partial Q}{\partial t} \r)^{-1} \frac{\partial Q}{\partial y_s}\r|_{t=t_s, y=y_s} & \text{ (Satz für implizite Funktionen)} \\
\frac{\partial y}{\partial t_s}(t) &= - W(t,t-s) f_2(t_s,y_s,p) & \text{ (Satz 1.6)} \\
\frac{\partial y}{\partial y_0} (\tend) &= W(\tend, t_s) \l[I - (f_1(t_s,y_s,p) \r. \\
& \l. \l. -f_2(t_s,y_s,p)) \l( \frac{\partial Q}{\partial t}\r)^{-1} \frac{\partial Q}{\partial y} \r|_{t=t_s, y=y_s} \r] W(t_s,t_0)
\end{align*}



\msection{Adjungierte Differentialgleichung}

Will man Matrix-Matrix-Produkte von links an $\tfrac{\partial y}{\partial y_0}$ oder $\tfrac{\partial y}{\partial p}$ berechnen:

\begin{align*}
u^T \frac{\partial y}{\partial y_0} & & \text{ mit } u\in\R^{n_y} \text{ oder} \\
U^T \frac{\partial y}{\partial y_0} & & \text{ mit } U \in \R^{n_y \times n}
\end{align*}

Berechnet man ebenfalls nicht zuerst $\frac{\partial y}{\partial y_0}$ und multipliziert dann, sondern löst die adjungierte Differentialgleichung.

\subsection*{Satz 1.12}

Gegeben sei das ODE-AWP

\[ \dot y = f(t,y,p), \quad y(t_0) = y_0 \quad (1.28) \]

Dann gilt: Integriert man die adjungierte Differentialgleichung (ADE)

\[ \dot \Lambda (t)^T = -\Lambda(t)^T \frac{\partial f}{\partial y} (t,y,p) \quad (1.29) \]

rückwärts, d.\,h. ausgehend von $T > t_0$ mit dem Anfangswert $\Lambda(T) = I$, dann gilt:

\begin{align*}
\frac{\partial y}{\partial y_0} (T) &= \Lambda (t_0)^T & (1.30) \\
\frac{\partial y}{\partial p} (T) &= \int\limits_{t_0}^T \Lambda(t)^T \frac{\partial f}{\partial p} (t,y,p) \dd t & (1.31)
\end{align*}

\emph{Beweis:}

Es gilt:

\begin{align*}
\dot y - f(t,y,p) &= 0 \\
\RA \int\limits_{t_0}^T \Lambda T (\dot y - f(t,y,p)) \dd t &= 0 & (1.32)
\end{align*}

Leite (1.32) nach $y_0$ ab:

\begin{align*}
0 &= \frac{\partial}{\partial y_0} \int\limits_{t_0}^T \Lambda^T (\dot y -f(t,y,p)) \dd t \\
&= \int\limits_{t_0}^T \Lambda^T \l( \frac{\partial \dot y}{\partial y_0} - \frac{\partial f}{\partial y} \frac{\partial y}{\partial y_0} \r) \dd t
\end{align*}

Partielle Integration:

\[ \int\limits_{t_0}^T \Lambda^T \frac{\partial \dot y}{\partial y_0} \dd t = \l[ \Lambda^T \frac{\partial y}{\partial y_0} \r]_{t_0}^T - \int\limits_{t_0}^T \dot \Lambda^T \frac{\partial y}{\partial y_0} \dd t \]

Daraus folgt:

\begin{align*}
0 &= \int\limits_{t_0}^T \Lambda^T \l( \frac{\partial \dot y}{\partial y_0} - \frac{\partial f}{\partial y_0} \frac{\partial y}{\partial y_0} \r) \dd t \\
&= \int\limits_{t_0}^T \l( -\dot \Lambda - \Lambda^T \frac{\partial f}{\partial y} \frac{\partial y}{\partial y_0} \r) \dd t + \l[\Lambda^T \frac{\partial y}{\partial y_0} \r]_{t_0}^T \\
&= \int\limits_{t_0}^T \underbrace{\l( -\dot \Lambda^T - \Lambda^T \frac{\partial f}{\partial y} \r)}_{= 0 \text{ adj. DGL}} \frac{\partial y}{\partial y_0} \dd t + \underbrace{\Lambda(T)^T}_{=I \text{ (AW)}} \frac{\partial y}{\partial y_0}(T) - \Lambda(t_0)^T \underbrace{\frac{\partial y}{\partial y_0}}_{=I} \\
&= \frac{\partial y}{\partial y_0} (T) - \Lambda(t_0)^T \\
\RA \Lambda^T(t_0) &= \frac{\partial y}{\partial y_0} (T) 
\end{align*}

Leite (1.32) nach $p$ ab mit analoger partieller Integration:

\begin{align*}
0 &= \int\limits_{t_0}^T \Lambda^T \l( \frac{\partial \dot y}{\partial p} - \frac{\partial f}{\partial y} \frac{\partial y}{\partial p} - \frac{\partial f}{\partial p} \r) \dd t \\
&= \int\limits_{t_0}^T \underbrace{\l( -\dot \Lambda^T - \Lambda^T \frac{\partial f}{\partial y} \r)}_{= 0} \frac{\partial y}{\partial p} \dd t - \int\limits_{t_0}^T \Lambda^T \frac{\partial f}{\partial p} \dd t + \underbrace{\Lambda^T}_{=I} \frac{\partial y}{\partial p}(T) - \Lambda^T(t_0) \underbrace{\frac{\partial y}{\partial p}(t_0)}_{=0} \\
&= -\int\limits_{t_0}^T \Lambda^T \frac{\partial f}{\partial p} \dd t + \frac{\partial y}{\partial p} (T) \\
\RA \frac{\partial y}{\partial p} (T) &= \int\limits_{t_0}^T \Lambda^T \frac{\partial f}{\partial p} \dd t
\end{align*}

\subsection*{Bemerkung 1.13}

Zur Berechnung von $\Lambda^T$ muss man erst vorwärts (1.28) lösen und $y$ berechnen, die Werte von $y$ dabei zwischenspeichern und dann rückwärts (1.29) lösen, um $\Lambda^T$ zu berechnen.

\subsection*{Ableitung von Linearkombinationen von $\frac{\partial y}{\partial y_0}$}

Gegeben: $u\in\R^{n_y}$ (adjungierte Richtung). Die Linearkombinations-ADE

\[ \partial_t (u^T \Lambda(t)^T) = - (u^T \Lambda (t)^T) \frac{\partial f}{\partial y} (t,y,p) \quad (1.23) \]

mit dem Anfangswert

\[ (u^T \Lambda(T)^T) = u^T \quad (1.34) \]

hat die Lösung

\begin{align*}
u^T \Lambda(t_0)^T &= u^T \frac{\partial y}{\partial y_0} (T) & (1.35) \\
\text{und } \int\limits_{t_o}^T (u^T \Lambda(t)^T) \frac{\partial f}{\partial p} (t,y,p) \dd t &= u^T \frac{\partial y}{\partial p} (T) & (1.36)
\end{align*}

D.\,h. pro Linearkombination der Zeilen von $\tfrac{\partial y}{\partial y_0}$ und $\tfrac{\partial y}{\partial p}$ muss nur eine Rückwärts-AWP gelöst werden.

\subsection*{Anwendung:}

\begin{align*}
& \Phi(y(T; t_0, y_0, p)) & & \text{ "`Zielfunktion"'} \\
& \Phi: \R^{n_y}  \to \R
\end{align*}

Gradient:

\[ \nabla_p \Phi(y(T; t_0, y_0,p)) = \frac{\partial \Phi}{\partial y} \frac{\partial y}{\partial p} (T; t_0,y_0,p) \]

benötigt nur eine adjungierte Richtung $\tfrac{\partial \Phi}{\partial y} \in \R^{n_y}$

\subsection*{Zusammenfassung:}

\begin{itemize}
\item Variationsdifferentialgleichung
\begin{itemize}
	\item Vorwärtsdifferentiation
	\item Richtungsableitungen
\end{itemize}
\item Adjungierte Differentialgleichung
\begin{itemize}
	\item Rückwärtsdifferentiation
	\item Linearkombinationen
\end{itemize}
\end{itemize}

\msection{Simulation und Optimierungsprobleme bei Differentialgleichungen}

% Bild siehe Seite 21 in Kapitel1.pdf

\begin{itemize}
\item \emph{Simulation:} Löse die Mathematischen Modellgleichungen, in dieser Vorlesung: Integration von ODE/DAE-AWPn
\item \emph{Optimierungsprobleme:}
\begin{itemize}
	\item \emph{Parameterschätzung:} Bestimme die Modellparameter $p$ so, dass Modell und Realität möglichst gut übereinstimmen.
	\item \emph{Modelldiskriminierung:} Bestimme durch Experimente, welche Modellvariante die Realität besser beschreibt.
	\item \emph{Optimale Versuchsplanung:} Bestimme Experimente, aus denen die Parameter mögliuchst signifikant geschätzt werden können.
	\item \emph{Optimales Design:} Berechne, wie ein System, Gerät etc. nach einem bestimmten Ziel optimal gebaut werden soll.
	\item \emph{Optimale Steuerung:} Berechne, wie ein Prozess nach einem bestimmten Ziel optimal durchgeführt werden soll, typischerweise: Minimale Kosten oder maximale Ausbeute.
	\item \emph{Optimale modellbasierte Regelung:} Wie ändert sich die optimale Steuerung bei Störungen des Systems?
\end{itemize}
\end{itemize}













